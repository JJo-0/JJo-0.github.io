---
title: "linux 개발환경 세팅, 설치 및 Bash 명령어"
date: 2025-06-17 16:40:00
categories:
  - 정리
  - 개발
  - Project
  - Dev
tags:
  - setting
  - linux
toc: true
toc_sticky: true
toc_label: "페이지 주요 목차"
---

## 주제

- 내가 쉽게 쓰기 위해서, 리눅스의 명령어, 썼던 제품들의 명령어등을 정리하고자 한다.

---

### 목차

|목차|내용|비고|링크|
|:--:|:--|:--|:--|
|**linux 설치**|리눅스 세팅|리눅스 세팅 방법|<a href="#linux-세팅">바로가기</a>|
|**Multi-Cuda Setting**|멀티 CUDA 환경 설정|여러 CUDA 버전 병행 사용|<a href="#multi-cuda-setting">바로가기</a>|
|**Google Drive 마운트**|WSL 2에서 Google Drive 마운트|rclone을 이용한 클라우드 스토리지 연동|<a href="#wsl-2에서-google-drive-마운트">바로가기</a>|
|**리눅스 명령어**|리눅스 명령어|시스템 확인 명령어, 디스크|<a href="#리눅스-명령어">바로가기</a>|
|**시스템 확인 명령어**|리눅스 시스템 확인 명령어|lsb_release, cat /etc/os-release, uname -a|<a href="#시스템-확인-명령어">바로가기</a>|


---
## Linux 세팅

### Cuda Setting
[https://jjo-0.github.io/%EC%A0%95%EB%A6%AC/dev/Multi-Cuda/](https://jjo-0.github.io/%EC%A0%95%EB%A6%AC/dev/Multi-Cuda/)  
멀티 쿠다 세팅을 남겨놨다.

### Multi-Cuda Setting

Multi-Cuda Setting을 해야하는 상황이 왔다. 실제로 내가 했던 방법을 정리할 생각이다.  
연구소에서 많은 AI 모델을 돌려야하는데, 모델마다 요구하는 CUDA 버전이 달랐다.

| 목차 | 설명 |
|:---:|:---:|
| [Window](#Window) | Window에서의 Multi-Cuda Setting |

#### Window

##### 환경
- Window 11
- WSL 2.0

#### CUDA ToolKit 설치 runfile (Local)

**설치 링크**  
[11.8](https://developer.nvidia.com/cuda-11-8-0-download-archive?target_os=Linux&target_arch=x86_64&Distribution=WSL-Ubuntu&target_version=2.0&target_type=runfile_local)  
[12.4](https://developer.nvidia.com/cuda-12-4-0-download-archive?target_os=Linux&target_arch=x86_64&Distribution=WSL-Ubuntu&target_version=2.0&target_type=runfile_local)  
[12.6](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=WSL-Ubuntu&target_version=2.0&target_type=runfile_local)  
[전체 Archive](https://developer.nvidia.com/cuda-toolkit-archive)

#### GCC 설치

CUDA 11.8의 경우 기본으로 설치되어 있는 gcc 버전 13.3과는 호환되지 않아서 다운 그레이드 해야한다.

**코드**

```bash
# ==============================
# 1) CUDA 기존 것 제거 (WSL 안에서)
# ==============================
sudo apt-get purge nvidia-cuda-toolkit # cuda 제거
sudo apt-get autoremove # 
sudo rm -rf /usr/local/cuda* 

# Gcc version 확인 코드
gcc --version

# gcc 12, 13 버전 설치
sudo apt-get install gcc-12 g++-12

# gcc 12 버전으로 변경
sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 60 --slave /usr/bin/g++ g++ /usr/bin/g++-12

# update-alternatives: 이 명령어는 여러 버전의 프로그램을 관리, 사용자가 선택할 수 있도록 대체 항목을 설정하는 도구.
# --install : 대체 항목을 추가
# /usr/bin/gcc: 이 경로는 gcc라는 명령어의 기본 위치를 지정 
# gcc: 이 부분은 대체 항목의 이름을 지정
# /usr/bin/gcc-12: 이 경로는 실제로 사용할 GCC의 버전(여기서는 GCC 12)의 위치를 지정
# 60: 이 숫자는 우선 순위 나타낸다. 여러 개의 대체 항목이 있을 때, 숫자가 높을수록 우선적으로 선택된다. 여기서 GCC 12의 우선 순위를 60 설정했다. 
# --slave /usr/bin/g++ g++ /usr/bin/g++-12: 이 부분은 "슬레이브" 항목을 설정하는 것입니다. 슬레이브 항목은 주 항목(여기서는 gcc)이 선택될 때 자동으로 선택되는 항목입니다. 즉, gcc가 gcc-12로 설정되면, g++도 자동으로 g++-12로 설정
  # /usr/bin/g++: 슬레이브 항목의 기본 위치입니다.
  # g++: 슬레이브 항목의 이름입니다.
  # /usr/bin/g++-12: 슬레이브 항목이 가리키는 실제 프로그램의 경로입니다.

# gcc 12 버전으로 변경 확인
gcc --version

# ==============================
# 2) Cuda 버전별 설치
# ==============================
# cuda 11.8 설치
sudo sh cuda_11.8.0_520.61.05_linux.run

# gcc 13 버전으로 변경
sudo apt install gcc-13 g++-13
sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-13 70 --slave /usr/bin/g++ g++ /usr/bin/g++-13
```

#### 나의 환경 설정

WSL에서 CUDA 설정 링크 참조 : [WSL](https://cjkangme.github.io/posts/2024-02-15-wsl2로-cuda-환경-설정하기-cudacudnn-설치까지/)  
WSL 관련 프로그램 설치 : [WSL_GUI_앱_실행](https://learn.microsoft.com/ko-kr/windows/wsl/tutorials/gui-apps)

```bash
# > ~/.bashrc file 내부

#####################
### User Setting ###
#####################

# Pyenv 초기화
export PATH="/home/jo/.pyenv/bin:$PATH"
eval "$(pyenv init --path)"
eval "$(pyenv virtualenv-init -)" # Miniforge3 경로 추가
export PATH="/home/jo/.pyenv/versions/miniforge3-24.11.0-1/bin:$PATH"

alias update='sudo apt update && sudo apt upgrade -y && sudo apt autoclean -y && sudo apt autoremove -y'

function switch_cuda {
    local version=$1
    local gcc_version

    case "$version" in
        11.3)
            gcc_version="gcc-9"
            cuda_path="/usr/local/cuda-11.3"
            ;;
        11.8)
            gcc_version="gcc-12"
            cuda_path="/usr/local/cuda-11.8"
            ;;
        12.4)
            gcc_version="gcc-13"
            cuda_path="/usr/local/cuda-12.4"
            ;;
        12.6)
            gcc_version="gcc-13"
            cuda_path="/usr/local/cuda-12.6"
            ;;
        *)
            echo "지원되지 않는 CUDA 버전입니다. 사용 가능한 버전: 11.3, 11.8, 12.4, 12.6"
            return 1
            ;;
    esac

    # GCC 전환
    sudo update-alternatives --set gcc /usr/bin/$gcc_version

    # CUDA 전환
    sudo update-alternatives --set cuda $cuda_path

    # 환경 변수 설정
    export PATH=$cuda_path/bin:$PATH
    export LD_LIBRARY_PATH=$cuda_path/lib64:$LD_LIBRARY_PATH

    echo "CUDA 버전 $version 로 전환되었습니다."
    gcc --version
    g++ --version
    nvcc --version
}
```

#### 명령어

```bash
#cudnn version 확인
dpkg -l | grep cudnn
```

#### Cuda 란?

CUDA(Compute Unified Device Architecture)는 NVIDIA가 개발한 병렬 컴퓨팅 플랫폼. CUDA를 통해 개발자들은 GPU의 병렬 처리 능력을 활용할 수 있게 되었습니다. CUDA는 GPU의 가상 명령어 집합과 병렬 연산 요소에 직접 접근할 수 있는 소프트웨어 계층을 제공하며, C 언어 등 표준 언어로 GPU 기반의 병렬 처리 알고리즘을 작성할 수 있습니다

1. CUDA의 주요 특징은 다음과 같습니다.
   1. 첫째, GPU의 병렬 처리 기능을 활용하여 계산해 다양한 분야에서 10배 이상의 성능 향상 시킴
   2. 둘째, 흩뿌린 읽기, 고속 공유 메모리, 정수 및 비트 단위 연산 지원 등 GPU 고유의 특성을 활용 가능
   3. 셋째, 저수준 API와 고수준 API를 모두 제공하여 개발자의 편의성 상승

CUDA의 개념, 특성, 버전별 차이점, 설치 및 구성 방법, 멀티 CUDA 환경 구축 등  
CUDA 플랫폼에 대한 전반적인 내용을 다루고자 합니다. 이를 통해 CUDA의 중요성과 활용 방법을 소개하고, 관련 기술에 대한 이해를 높이고자 합니다.

#### CUDA 개념

CUDA(Compute Unified Device Architecture)는 NVIDIA가 개발한 병렬 컴퓨팅 플랫폼이다.  
GPU는 CPU와 달리 병렬 다수 코어 구조를 가지고 있어, 수천 개의 스레드를 동시에 실행할 수 있다.

#### CUDA 특징

1. GPU 고유 특성을 활용해 병렬 처리에 최적화된 환경을 제공합니다.
2. 디바이스 상에서 읽기·쓰기 속도가 호스트보다 빠르며, 공유 메모리를 통한 고속 데이터 처리가 가능합니다.

#### CUDA 버전별 차이점

CUDA는 2007년 1.0부터 시작하여 2.0(2008), 3.0(2010), 4.0(2011), 5.0(2012), 6.0(2014), 7.0(2015), 8.0(2016), 9.0(2017), 10.0(2018), 11.0(2020) 등으로 꾸준히 발전해 왔습니다. 각 버전에서는 병렬 처리·메모리 관리 개선, SIMD(Single Instruction, Multiple Data) 처리 성능 향상, 에너지 효율 개선, 새로운 GPU 아키텍처 지원 등이 추가되었습니다.

버전별 하드웨어 및 소프트웨어 호환성도 중요합니다. 예를 들어, 특정 버전은 특정 GPU 아키텍처에 최적화되며, 운영 체제·컴파일러·라이브러리와의 호환성을 구성 시 반드시 확인해야 합니다.

#### CUDA 설치 고려사항

1. 시스템 요구사항과 호환성: 최소 GPU 아키텍처와 커널 버전을 만족해야 하며, Pascal 이상의 GPU 사용이 권장됩니다.
2. NVIDIA 드라이버 설치: Windows에서는 최신 x86 프로덕션 드라이버(R495 이상), Linux 환경에서는 CUDA Toolkit 패키지를 사용합니다.
3. 개발 환경 준비: Windows, Linux, WSL 등 각 환경마다 설치 법이 다르므로 유의해야 하며, 일부 개발자 도구나 Unified Memory 기능에 제한 사항이 있을 수 있습니다.

#### 멀티 CUDA 환경 구성

아래는 Windows, Linux, WSL 등에서 CUDA를 병행 사용하기 위한 핵심 사항입니다.

- Windows
  - 최신 프로덕션 드라이버(R495 이상) 설치.
  - WSL 2 설정 후 Ubuntu 등 Linux 배포판을 설치해 CUDA Toolkit 이용.
  - 드라이버 충돌 없이 멀티 GPU 환경을 구성 가능.

- Linux
  - 준수하는 GPU 아키텍처 및 최신 패키지 확인.
  - CUDA Toolkit 설치 시, 기존 드라이버 충돌를 피해야 함.
  - Maxwell GPU 미지원 이슈가 있으나 실제로 동작할 수도 있음.

- WSL
  - Windows 드라이버만 설치하면 됨. WSL 내부에서 Linux 드라이버 추가 설치 필요 없음.
  - nvidia-smi 명령어 위치, Unified Memory 제약, 멀티 GPU 선택 제한 등에 유의해야 함.
  - 커널 버전(4.19.121 이상, 5.10.16.3 이상 권장) 및 Pascal 이상의 GPU 요구.

#### 자주 발생하는 문제와 해결책

- 경쟁 상태(Race Condition): 공유 자원 접근 시 동기화 기법 사용.
- 교착 상태(Deadlock): 자원 할당 순서 지정으로 스레드 간 충돌 방지.
- 라이브락(Livelock): 타임아웃 등 기법으로 스레드 간 상호작용 최소화.
- 확장성(Scalability): 알고리즘 최적화·메모리 효율화·데이터 분할로 병렬 처리 성능 향상.

#### 추가 학습 자료

- NVIDIA CUDA 공식 문서: https://docs.nvidia.com/cuda/
- 서적: "CUDA by Example" (Jason Sanders, Edward Kandrot)
- 포럼: https://forums.developer.nvidia.com/c/gpu-computing/cuda/
- Stack Overflow CUDA 태그: https://stackoverflow.com/questions/tagged/cuda

#### 결론

CUDA는 병렬 컴퓨팅 분야에서 중요한 역할을 담당하며, 다양한 버전과 아키텍처를 통해 GPU의 강력한 성능을 활용할 수 있게 합니다. Windows·Linux·WSL 등 여러 환경에서 사용 가능하며, 설치 시 드라이버·GPU 아키텍처 호환성·개발 툴 제한 사항 등을 주의해야 합니다. 앞으로도 CUDA는 인공지능·머신러닝·데이터 과학 등 분야에서 발전을 거듭하며, GPU 병렬 처리 기술의 핵심으로 자리 잡을 것입니다. 

### Ros2 Humble && Jazzy

#### ROS 2 Distro Switcher  
**ROS 2 Humble** 과 **ROS 2 Jazzy** 배포판을 손쉽게 전환할 수 있는 쉘 함수와 alias 설정이다.

##### 📦 요구 사항

- Ubuntu 22.04 이상 (Humble), Ubuntu 24.04 (Jazzy 권장) 설치가 완료되어야 한다.
- 나의 경우 24.04 버전에 **RoboStack** 이용해 설치 했다.
  - 시스템 의존성 없이 다양한 OS에서 ROS2 설치 가능한, conda-forge 위에  올라간 ROS2 배포 binary project
  - RoboStack을 이용해 설치한 경우 밑의 것이 필요가 없다. (Conda activate 만으로 설정 완료됨)
- `/opt/ros/humble` 및 `/opt/ros/jazzy` 경로에 ROS 2 설치
- Bash 또는 Zsh 쉘  

- 🛠️ 커스텀 옵션
  - ROS_DOMAIN_ID 및 ROS_LOCALHOST_ONLY 값은 필요에 따라 조정
  - Colcon workspace 설정이 필요하면, switch_ros 함수 내에 추가 source ~/your_ws/install/setup.bash 라인을 넣어 확장 가능하다.
  - 여러 workspace를 배포판별로 관리하려면 ~/.bashrc 안에 source ~/ws_humble/install/setup.bash 와 source ~/ws_jazzy/install/setup.bash 구문을 각 case 블록에 추가.  
  - GUI가 필요한 경우 X 서버(VcXsrv, XQuartz) 설정과 DISPLAY 환경 변수를 확인해야 한다.  

```bash
# ~/.bashrc 또는 ~/.zshrc
# ───────── ROS 버전 스위처 ─────────
function switch_ros {
    local distro="$1"
    case "$distro" in
        humble)
            source /opt/ros/humble/setup.bash
            export ROS_DOMAIN_ID=0
            export ROS_LOCALHOST_ONLY=0
            ;;
        jazzy)
            source /opt/ros/jazzy/setup.bash
            export ROS_DOMAIN_ID=0
            export ROS_LOCALHOST_ONLY=0
            ;;
        *)
            echo "Usage: switch_ros {humble|jazzy}"
            return 1
            ;;
    esac
    echo "Switched to ROS 2 $distro"
    ros2 --version
}

alias ros_humble='switch_ros humble'
alias ros_jazzy='switch_ros jazzy'
```
  
설정 파일 적용:  

```bash
source ~/.bashrc   # 또는 source ~/.zshrc

# "#" 제거하고 원하는 명령어 적용
# Humble 환경 전환 
# ros_humble 
# switch_ros humble

# Jazzy 환경 전환 
# ros_jazzy
# switch_ros jazzy
```

### WSL 2에서 Google Drive 마운트

WSL 2에서 Google Drive를 마운트하려면 **`rclone`**이라는 도구를 사용하는 것이 가장 일반적이고 안정적인 방법이다. `rclone`은 다양한 클라우드 저장소를 로컬 파일 시스템처럼 연결해주는 강력한 프로그램이다.

#### 1단계: `rclone` 설치하기

먼저 WSL 터미널(예: Ubuntu)을 열고 아래 명령어를 실행하여 `rclone`을 설치한다. `apt`로 설치하는 것보다 공식 스크립트를 사용하는 것이 최신 버전을 설치하는 데 더 좋다.

```bash
curl https://rclone.org/install.sh | sudo bash
```

설치가 완료되면 아래 명령어로 버전을 확인하여 제대로 설치되었는지 검증한다.

```bash
rclone --version
```

#### 2단계: `rclone`으로 Google Drive 연동 설정하기

이제 `rclone`이 Google Drive 계정에 접근할 수 있도록 설정해야 한다.

1. 터미널에 `rclone config`를 입력하여 설정 도구를 실행한다.

```bash
rclone config
```

2. 설정 도구의 질문에 아래와 같이 차례대로 답변한다.

- `n) New remote` -> **`n`**을 입력하고 Enter를 누른다.
- `name>` -> 원격 연결의 이름을 정한다. **`gdrive`** 라고 입력하는 것을 추천한다.
- `Storage>` -> 목록에서 Google Drive를 찾는다. 번호가 매번 다를 수 있으니, **`drive`**를 입력하고 Enter를 치면 쉽게 찾을 수 있다. 해당 번호를 입력하고 Enter를 누른다.
- `client_id>` -> 그냥 **Enter**를 눌러 기본값을 사용한다.
- `client_secret>` -> 그냥 **Enter**를 눌러 기본값을 사용한다.
- `scope>` -> Google Drive에 대한 접근 권한을 선택한다. 전체 권한을 위해 **`1`**을 입력하고 Enter를 누른다.
- `root_folder_id>` -> 그냥 **Enter**를 누른다. (특정 폴더만 마운트할 게 아니라면 비워둔다.)
- `service_account_file>` -> 그냥 **Enter**를 누른다.
- `Edit advanced config?` -> **`n`**을 입력하고 Enter를 누른다.
- `Use auto config?` -> **`y`**를 입력하고 Enter를 누른다.
  - 이 단계를 진행하면 **Windows의 기본 웹 브라우저가 자동으로 열린다.** 브라우저에서 Google 계정으로 로그인하고, `rclone`이 Google Drive 파일에 접근하는 것을 허용해 준다.
- `Configure this as a team drive?` -> 개인 드라이브를 사용한다면 **`n`**을 입력하고 Enter를 누른다.
- `Yes this is OK` -> 설정이 맞는지 확인 후, **`y`**를 입력하고 Enter를 누른다.
- 마지막으로 **`q`**를 입력하여 설정 도구를 종료한다.

#### 3단계: Google Drive 마운트하기

이제 설정이 완료되었으니 실제로 Google Drive를 WSL의 폴더에 연결(마운트)할 차례다.

1. **마운트 지점(Mount Point) 생성**: Google Drive를 연결할 비어있는 폴더를 홈 디렉터리에 만든다.

```bash
mkdir -p ~/gdrive
```

2. **Google Drive 마운트**: 아래 명령어를 실행하여 앞서 설정한 `gdrive` 원격 연결을 `~/gdrive` 폴더에 마운트한다.

```bash
rclone mount gdrive: ~/gdrive --daemon
```

- `gdrive:`는 2단계에서 만든 원격 연결 이름이다. **반드시 콜론(`:`)을 붙여야 한다.**
- `~/gdrive`는 방금 만든 마운트 지점 폴더다.
- `--daemon` 옵션은 `rclone`이 백그라운드에서 실행되게 하여, 마운트 후에도 터미널을 계속 사용할 수 있게 해준다.

3. **마운트 확인**: `ls` 명령어로 마운트한 폴더의 내용을 확인해 본다. Google Drive의 파일과 폴더 목록이 보이면 성공이다.

```bash
ls ~/gdrive
```

#### 마운트 해제 및 자동 마운트

**마운트 해제**: Google Drive 연결을 끊고 싶을 때는 아래 명령어를 사용한다.

```bash
fusermount -u ~/gdrive
```

**WSL 시작 시 자동 마운트**: 매번 WSL을 켤 때마다 자동으로 마운트되게 하려면, `~/.bashrc` 파일 맨 아래에 다음 스크립트를 추가한다. (사용하는 쉘이 zsh라면 `~/.zshrc`에 추가)

1. `nano ~/.bashrc` 명령어로 편집기를 연다.
2. 파일 맨 아래에 아래 내용을 붙여넣는다.

```bash
# Google Drive 자동 마운트
if ! mount | grep -q "on ${HOME}/gdrive type fuse.rclone"; then
  rclone mount gdrive: ~/gdrive --daemon
fi
```

3. `Ctrl+X` -> `Y` -> `Enter`를 눌러 저장하고 종료한다. 이제 새 터미널을 열면 자동으로 마운트가 시도된다.


## 리눅스 명령어

### 시스템 확인 명령어

```bash
# 우분투 시스템 확인 명령어
lsb_release -a 
# 출력 예시
# No LSB modules are available.
# Distributor ID: Ubuntu
# Description:    Ubuntu 20.04.2 LTS
# Release:        20.04
# Codename:       focal

cat /etc/os-release 
# 출력 예시
# NAME="Ubuntu"
# VERSION="20.04.2 LTS (Focal Fossa)"
# ID=ubuntu
# ID_LIKE=debian
# HOME_URL="https://www.ubuntu.com/"
# SUPPORT_URL="https://help.ubuntu.com/"
# BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
# PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
# VERSION_CODENAME=focal
# UBUNTU_CODENAME=focal

# 시스템 정보 확인
uname -a 
# 출력 예시
# Linux DESKTOP-1 5.4.0-105-generic #118-Ubuntu SMP Fri Jun 4 08:59:58 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux 
# 출력 설명 : <시스템 이름 : Linux> <호스트 이름 : DESKTOP-1> <커널 버전 : 5.4.0-105-generic> <빌드 날짜 : #118-Ubuntu SMP Fri Jun 4 08:59:58 UTC 2021> <아키텍처 : x86_64 x86_64 x86_64> <운영체제 : GNU/Linux>


```

### 디스크

```bash

# 파티션 확인
sudo fdisk -l # 파티션 확인
lsblk # 블록 디바이스 목록 확인

# 디스크 포맷
sudo mkfs.vfat -F 32 -n "USB" /dev/sdb1 # FAT32 파일 시스템으로 포맷
sudo mkfs.ext4 -L "USB" /dev/sdb1 # ext4 파일 시스템으로 포맷
# 주로 리눅스 시스템에서 사용하는 ext4 파일 시스템이다, 
# 모든 os에 적용 하고 싶으면 e


sudo dmesg # dmesg란 커널 메시지를 확인하는 명령어

# 현 디렉토리 사용량 계산
du -sh * | sort -rh | less # 현재 디렉토리,디스크 사용량을 계산하라는 의미
# 예시 sudo du -h / | sort -rh | head -n 10 # 용량이 만약 100% 사용중이라면 sort 명령어도 안먹을 것이다.
sudo du -h / 2>/dev/null | grep '[0-9]G' # 어떤 파일 공간 차지하는지 확인 (Sort 없이)
sudo du -h / | sort -rh | head -n 10 # 공간이 남아 있을 경우 

#확인 디스크 공간 보기
sudo df -h 

# 캐시 삭제
sudo apt-get autoremove -y && sudo apt-get autoclean
conda clean --all # Conda 캐시 삭제
pip cache purge # Pip 캐시 삭제
```  

<details>
  <summary>
    du 명령어 설명
  </summary>
  <pre>
    du (Disk Usage): 파일 및 디렉토리의 디스크 공간 사용량을 추정하는 명령어 즉, 각 파일, 디렉토리가 디스크 공간을 차지하고 있는지 계산해주는 것  
    옵션:  
    -s (summarize): summarize 옵션은 각 파일이나 디렉토리에 대한 총 사용량만 표시 하위 디렉토리나 파일별 상세 용량 대신, 각 항목의 총합만 보여줌  
    -h (human-readable): human-readable 옵션은 파일 크기를 사람이 읽기 쉬운 형식으로 출력. 예) 바이트 단위 대신 킬로바이트(K), 메가바이트(M), 기가바이트(G) 등으로 자동으로 변환함  
    '*' : 와일드카드 문자. 모든 파일 및 디렉토리를 의미.  
    | (파이프): 파이프 기호는 앞선 명령어의 표준 출력을 뒤따르는 명령어의 표준 입력으로 연결해주는 역할 
      
    sort: 텍스트 파일의 행, 명령어의 출력을 정렬  
    옵션 :  
    -r (reverse): 역순으로 정렬  
    -h (human-readable): 사람이 읽기 쉬운 형식으로 출력  
    -n (numeric): 숫자 형식으로 정렬  
    -k (key): 특정 필드를 기준으로 정렬  
    -t (field): 특정 필드를 기준으로 정렬  
    -u (unique): 중복 제거  
    
    less : 텍스트 파일을 페이지 단위로 표시하는 명령어  
    옵션 :  
    -p (pattern): 패턴 검색  
    -N (number): 행 번호 표시  
    -R (raw): 이스케이프 시퀀스 무시  
    -S (squeeze): 너무 긴 행을 잘라서 표시  
  </pre>
</details>

<details>
  <summary>
    캐시 삭제 설명
  </summary>
  <pre>
    sudo apt-get autoremove -y :  
    
    <b>삭제 되는 것</b>
    현재 시스템에서 사용되지 않는 패키지들이 삭제된다.<br>
    주로 /var/lib/apt와 /usr/lib에 설치된 라이브러리나 실행 파일들이 대상 <br>

    <b>삭제 되지 않는 것</b>
    사용자가 직접 설치한 패키지(의존성이 아닌 패키지)는 유지된다.<br>
    설정 파일(/etc)이나 사용자 데이터는 건드리지 않는다.
  </pre>
</details>

## PC 명령어

### Jetson AGX Orin, Xavier NX, Jetson Nano

```bash
# 시스템 정보 확인
# Jetson Orin NX의 CPU, GPU, 메모리 사용량, 온도 등 실시간 시스템 상태를 모니터링
sudo tegrastats
```

#### jtop 설명
Jetson Orin NX의 CPU, GPU, 메모리 사용량, 온도 등 실시간 시스템 상태를 모니터링
```bash
# 실행 방법
sudo jtop

# 설치 방법
sudo apt update
sudo apt install -y python3-pip
sudo pip3 install -U jetson-stats
```

**첫번째 페이지 : All**
- 상단
  - Model : 사용중인 Jetson 모델명
  - Jetpack : 사용중인 Jetpack 버전
  - L4T : 사용중인 L4T 버전
- 중단
  - CPU : CPU 코어별 사용량 (% 형식 예: [ 10%]])
  - Mem : RAM 사용량 (현재 사용량 / 전체 용량) 예 : [ 4.8G/61.4G ]

---

#### jetson-pytorch 설명
Jetson Orin NX의 경우 PyTorch 시스템 설치가 다르다, 이를 설치하기 위해서는 아래 명령어를 사용한다.  
Site 나와 있는 대로 하면 된다.   
[링크_Pytorch](https://docs.nvidia.com/deeplearning/frameworks/install-pytorch-jetson-platform/index.html) 파이토치 설치 사이트  
[링크_JetPack](https://developer.nvidia.com/embedded/jetpack) : 제트팩 설치 사이트  
[링크_cuSPARSELt](https://docs.nvidia.com/cuda/cusparselt/index.html) : 여기서 다운로드링크 있음  
[링크_호환체크표](https://docs.nvidia.com/deeplearning/frameworks/install-pytorch-jetson-platform-release-notes/pytorch-jetson-rel.html#pytorch-jetson-rel) : 호환체크표 여기서 맞는 것을 고르고 설치 하면 된다.  
[링크_vision](https://github.com/pytorch/vision) : torchvision 설치 사이트, 자신 torch, Python 버전에 맞게  

##### torch, torchvision, torchaudio에 대한 간략한 설명

**Pytorch**  
**Pytorch 란** : Facebook이 주도하여 개발한 오픈 소스 딥러닝 프레임워크  
**Dynamic Computation Graph** : PyTorch는 동적 계산 그래프를 지원해 코드 작성시 유연, 디버깅 용이  
**GPU 가속화 자동 미분 기눙(autograd)** : PyTorch는 자동 미분을 지원해 딥러닝 모델 학습시 역전파 알고리즘을 자동으로 수행  
[Pytorch_설명_링크](https://pytorch.org/docs/stable/index.html)  

**TorchVision**  
**TorchVision 란** : PyTorch와 함께 제공하는 컴퓨터 비전 라이브러리  
데이터셋, 모델, 이미지변환(Transforms), 데이터 로더 등을 제공해 컴퓨터 비전 작업을 쉽게 수행할 수 있도록 도와줌  
이미지 전처리, 학습 과정 단순화  
**데이터 로딩** : CIFAR, ImageNet, MNIST 등 다양한 공개 이미지 데이터셋을 쉽게 불러올 수 있습니다.  
모델 아키텍처: ResNet, VGG, Faster R-CNN 등 사전 학습된 모델을 제공하여, 전이 학습(Transfer Learning) 및 모델 비교가 용이합니다.  
이미지 변환: 이미지 크기 조정, 자르기, 정규화 등 다양한 이미지 전처리 작업을 위한 함수들이 포함
[Github_설명_링크](https://github.com/pytorch/vision)  

**Torchaudio**
Torchaudio 란 : PyTorch와 함께 제공하는 오디오 처리 라이브러리  
오디오 입출력(I/O), 오디오 전처리, 변환(예: 스펙트로그램, MFCC 등) 기능을 제공하며, PyTorch의 텐서와 완벽하게 연동됨  
오디오 데이터 로딩: WAV, MP3 등 다양한 포맷의 오디오 파일을 쉽게 읽고 쓸 수 있습니다.  
오디오 전처리: 오디오 신호의 스펙트럼 분석, 노이즈 제거, 증강(Augmentation) 등의 작업에 활용됩니다.  
응용 분야: 음성 인식, 음악 분류, 오디오 이벤트 감지 등 오디오 기반의 딥러닝 모델 개발에 주로 사용됩니다.  
[Github_설명_링크](https://github.com/pytorch/audio)

```bash
# 1 - Jetpack 설치, (2025.02기준) 최신판 6.2
# 나의 경우 다른 분이 이미 깔았던 상황이라, 이 부분은 생략(나의 경우 6.0이었음)

# 2 - PyTorch 요구 시스템 패키지 설치
sudo apt-get -y update
sudo apt-get install -y  python3-pip libopenblas-dev

# 3 - 24.06 PyTorch 또는 이후 버전을 설치하는 경우, cusparselt를 먼저 설치
# 위에 링크로 다운로드 설치 (1번째 사이트는 잘 안되었음..)

# 4 - Multiple PyTorch 위한 conda 환경 생성, {} 여기에 자신이 원하는 이름을 넣어주면 된다.  
conda create -n  {conda_env name} python=3.10
conda activate {conda_env name}

# 5 - PyTorch 설치
# 나의 경우 여기서 시간이 많이 잡아먹음
# 6.0 버전이라 https://developer.download.nvidia.cn/compute/redist/jp/v60/pytorch/ 그 이후 버전을 찾아야했다.
# 여러가지는 다 넣었는데 안되어서 그냥 https://developer.download.nvidia.cn/compute/redist/jp/v60/pytorch/ 다 다운 받기로 명령어 치니까
# 재귀적 다운로드 옵션(모든 파일 구조 다운로드 시도)
#   wget -r -np -nd https://developer.download.nvidia.cn/compute/redist/jp/v60/pytorch/

# 그래서 얻은 파일 이름
#   torch-2.4.0a0+07cecf4168.nv24.05.14710581-cp310-cp310-linux_aarch64.whl
#   torch-2.4.0a0+3bcc3cddb5.nv24.07.16234504-cp310-cp310-linux_aarch64.whl (선택해서 다운로드 받음)
#   torch-2.4.0a0+f70bd71a48.nv24.06.15634931-cp310-cp310-linux_aarch64.whl
export TORCH_INSTALL=https://developer.download.nvidia.cn/compute/redist/jp/v60/pytorch/torch-2.4.0a0+3bcc3cddb5.nv24.07.16234504-cp310-cp310-linux_aarch64.whl # 자신에게 맞는 버전 선택해야한다.
python3 -m pip install --no-cache $TORCH_INSTALL

# pytorch 설치 확인
python3 -c "import torch; print('PyTorch 버전:', torch.__version__); print('CUDA 사용 가능 여부:', torch.cuda.is_available())"
# 출력 나온다
# 예시 
# PyTorch 버전: 2.4.0a0+3bcc3cddb5.nv24.07
# CUDA 사용 가능 여부: True

# 6 - torchvision 설치
git clone --branch release/0.19 https://github.com/pytorch/vision.git # 나의 경우 0.19 버전을 설치
cd vision
python3 setup.py install
  # torchvision 설치 확인
python3 -c "import torchvision; print('torchvision 버전:', torchvision.__version__)"
python3 -c "import torchaudio; print('torchaudio 버전:', torchaudio.__version__)"

```

