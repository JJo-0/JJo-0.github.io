---
layout: single
title: "선형 대수"
categories: [ ]
tag: [ ]
toc: true
author_profile: false
sidebar:
    nav: "docs"
---

✅ Step 1: 이미지 기반 개념 정리 및 블로그 초안 구성 시작

이 글은 사용자가 제공한 두 장의 이미지에서 다루고 있는 “벡터 및 행렬 노름(norms)” 개념을 바탕으로 작성된 블로그 포스트입니다. 주요 수학 정의, 수식, 성질, 예시 등을 모두 포함하며, 머신러닝에서의 활용 가능성도 간략히 소개합니다.

⸻

📐 벡터와 행렬의 노름(Norms): 선형대수학의 기본이자 머신러닝의 핵심 개념

📌 메타 설명 (Meta Description)

벡터의 “길이”를 측정하는 수학적 도구인 노름(norm)은 선형대수학뿐만 아니라 머신러닝의 손실 함수, 정규화, 최적화 알고리즘 등 다양한 분야에서 핵심적으로 사용됩니다. 본 글에서는 ℓ₁, ℓ₂, ℓ∞ 및 Frobenius Norm 등 다양한 노름의 수학적 정의와 성질을 예제 중심으로 정리합니다.

⸻

1. 노름(Norm)이란?

노름(norm)은 벡터 또는 행렬의 길이(length) 또는 **크기(magnitude)**를 측정하는 함수입니다.
예를 들어, 흔히 사용하는 유클리디안 노름(Euclidean norm) 또는 ℓ₂ 노름은 다음과 같이 정의됩니다:

\|\mathbf{x}\|2 = \sqrt{\sum{i=1}^{N} x_i^2}

이것은 우리가 2차원 또는 3차원 공간에서 벡터의 길이를 구하는 방식과 같습니다.
보다 일반적으로는 다음과 같은 형태로 표현됩니다:

\|\mathbf{x}\|_2^2 = \mathbf{x}^\top \mathbf{x}

⸻

2. 노름의 수학적 정의와 네 가지 성질

노름은 다음의 4가지 수학적 조건을 만족하는 함수 f: \mathbb{R}^N \to \mathbb{R} 입니다:
	1.	비음수성(Non-negativity):
\forall \mathbf{x} \in \mathbb{R}^N,\quad f(\mathbf{x}) \ge 0
	2.	양의 정부호성(Definiteness):
f(\mathbf{x}) = 0 \iff \mathbf{x} = \mathbf{0}
	3.	동차성(Homogeneity):
\forall t \in \mathbb{R},\quad f(t\mathbf{x}) = |t|f(\mathbf{x})
	4.	삼각 부등식(Triangle inequality):
f(\mathbf{x} + \mathbf{y}) \le f(\mathbf{x}) + f(\mathbf{y})

이 네 가지는 노름이라는 수학적 객체를 정의하는 핵심 요소입니다.

⸻

3. 주요한 벡터 노름의 종류

🔹 ℓ₁ 노름 (Manhattan norm)

\|\mathbf{x}\|1 = \sum{i=1}^{N} |x_i|

모든 절댓값의 합을 통해 벡터의 크기를 측정합니다. 로버스트한 특성 덕분에 정규화(regularization)에서 자주 사용됩니다 (예: Lasso).

⸻

🔹 ℓ∞ 노름 (Maximum norm)

\|\mathbf{x}\|_\infty = \max_i |x_i|

가장 큰 절댓값 하나만으로 전체 크기를 측정합니다. 제한 조건 기반 최적화에 자주 등장합니다.

⸻

🔹 ℓₚ 노름 (General p-norm)

\|\mathbf{x}\|p = \left(\sum{i=1}^{N} |x_i|^p \right)^{1/p} \quad \text{for } p \ge 1

ℓ₁, ℓ₂, ℓ∞는 사실 모두 ℓₚ 노름의 특수한 경우입니다:
	•	p = 1: ℓ₁ norm
	•	p = 2: ℓ₂ norm
	•	p \to \infty: ℓ∞ norm

ℓₚ 노름은 p의 값에 따라 벡터 길이를 측정하는 기준이 달라집니다.
p < 1인 경우는 수학적으로 norm이 아니므로 제외됩니다.

⸻

4. 행렬의 노름: Frobenius Norm

벡터뿐 아니라 **행렬(matrix)**에도 노름을 정의할 수 있습니다. 가장 대표적인 예는 Frobenius 노름입니다.

\|\mathbf{A}\|F = \sqrt{\sum{i=1}^{M} \sum_{j=1}^{N} A_{i,j}^2} = \sqrt{\text{tr}(\mathbf{A}^\top \mathbf{A})}

이는 행렬을 벡터로 평탄화한 후, ℓ₂ 노름을 적용한 것과 동일합니다.
컴퓨터 비전, 행렬 분해, 딥러닝 모델의 weight decay 등에서 자주 쓰입니다.

⸻

5. 머신러닝에서의 활용
	•	Regularization (정규화)
	•	ℓ₁ 정규화: sparsity 유도 (Lasso)
	•	ℓ₂ 정규화: weight decay (Ridge, Tikhonov)
	•	Loss Functions
	•	Mean Squared Error (MSE): ℓ₂ norm 기반
	•	Mean Absolute Error (MAE): ℓ₁ norm 기반
	•	Optimization Constraints
	•	노름 제한을 통해 모델 복잡도 제어

⸻

✅ 정리 및 마무리
	•	노름은 벡터/행렬의 크기를 측정하는 기본적인 도구이다.
	•	ℓ₁, ℓ₂, ℓ∞ 모두 ℓₚ 노름의 특별한 경우로 이해할 수 있다.
	•	머신러닝에서 모델 성능과 일반화를 위한 핵심 도구로 사용된다.

⸻